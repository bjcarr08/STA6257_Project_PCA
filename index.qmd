---
title: "PCA (principal component analysis)"
author: "Brandy, Lee, Tavish"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
    highlight: pygments
course: STA 6257 - Advance Statistical Modeling
bibliography: references.bib # file contains bibtex for references
always_allow_html: true # this allows to get PDF with HTML features
editor: 
  markdown: 
    wrap: 72
---

```{=html}
<style>
 .title {
    color: #191970;    
  }
 .subtitle {
    color: #191970;
  }
  .author {
    color: #191970;
}
 .date {
    color: #191970;
  }
 body {
    background-color: #FAFAF5;
  }
</style>
```
## [Introduction]{style="color: #191970;"}

[**1. A comparative dimensionality reduction study in telecom customer
segmentation using deep learning and PCA**]{style="color: #8B814C;"}

[This article compares PCA with a deep learning autoencoder on telecom
customer data. Goal is to segment customers based on 220 features to
optimize customer satisfaction/loyalty. Raw data must be cleaned &
standardized (z-score normalization) before applying PCA. A scree plot
was used to visualize the number of features to keep, which was 3 that
explain \~72% of data. Using the absolute values of the eigenvectors
they can decide wich features contribute the most to the first 3 PC's.
Overall PCA saved \~90% of total variance with just 20 features,
reducing original dataset by 200. [@Alkha]]{style="color: #8B814C;"}

[**2. Visualizing Psychological Networks: A Tutorial in
R**]{style="color: #8B814C;"}

[Article aims to guide researchers on choosing the best/most
interpretable visualizations of psychological networks. These networks
include mental disorder symptoms (specifically OCD and depression) and
the connections/correlations between them. When plotting, the symptoms
are referred to as nodes and their connections as edges. The article
goes on to compare 4 different plotting approaches; force-directed
algorithms, multidimensional scaling, PCA, and eigenmodels. 6 different
benefits were used as a checklist for all 4 approches. Benefits include:
node placement is meaningful, useful for comparing replications,
distances between nodes is interpretable, X/Y placement of nodes is
interpretable, can be based on any network, central nodes in the center.
PCA checks 3 of the 6 benefits, node placement is meaningful, useful for
comparing replications, and X/Y placement of nodes is interpretable
(this being the primary benefit since nodes/symptoms can be compared
right to left, X, or top from bottom Y). 1 major disadvantage of PCA is
that it relies on the correlation matrix and nodes/symptoms can be
difficult to see when they score similarly on both PC's.
[@Jones]]{style="color: #8B814C;"}

[**3. SVM and PCA Based Learning Feature Classification Approaches for
E-Learning System**]{style="color: #8B814C;"}

[This article aims to classify student learning attributes using PCA in
order to develop a simple methodology to optimize a students dynamic
learning sequence based on their individual skill, needs and
preferences, and also to maximize their learning outcome in computer
programming courses (java, C). The study uses 8 different learning
attributes; anxiety, personality, learning style, cognitive style,
grades from prev. semester, motivation, study level, and student prior
knowledge. 100 students taking C programming course were used in the
present study. Each student filled out a questionairre to gather
information on the 8 learning attributes. They each took a 20 question
midterm and also a final that scored their capabilities in 3 areas;
syntax, logical, and application (each score was divided into low, med,
and high categories). For this study, 3 PC's were kept & used for
classification purposes and explain \~77% of the variance. From figure 5
it looks like the first PC is comprised of 3 main learning attributes
prior knowledge, learning style, and personality. Second PC groups
motivation, cognitive style, and grades from prev. semester. Third PC
groups anxiety with study level. The article then goes on to use the 3
PC's to fit 4 classification models, a neural network, quadratic SVM,
gaussian SVM, and linear SVM. Linear SVM provided the highest accuracy,
sensitivity, and specificity, outperforming the other kernal
classifiers. [@Khamp]]{style="color: #8B814C;"}

[**4. Applied Multivariate Statistical Analysis and Related Topics with
R**]{style="color: #8B814C;"}

[This chapter goes over PCA basic's and how and why it is useful. The
overall goal of PCA is to minimize the number of predictive variables
while maintaining most of the variation (70%\~80% as a guideline, the
book goes on to cover a few more rules of thumb for this). PCA is a good
method for finding outliers since the principal components are linear
combinations of the original data - plotting with lower dimensions makes
them easier to spot. PCA is also useful when some of the predictor
variables in a regression model are highly correlated, which if not
addressed can lead to poor parameter estimates. The first PC explains
the most variability in the data & each succeeding PC explains the most
possible remaining variability. PCA analysis should be preformed on
scaled/unit data, magnitudes must be comparable (use the correlation
matrix instead of covariance OR standardize the data).
[@lang2021applied]]{style="color: #8B814C;"}

[**5. The fixed effects PCA model in a common principal component
environment**]{style="color: #8B814C;"}

[The article compares a fixed effects PCA model to the 2 most common
approaches, descriptive algebraic and probabilistic. All three produce
the same results using spectral decomposition of the sample covariance
matrix but, the interpretations will differ depending on the
assumptions. Graphing the low dimensional PC's (usually the first 2) is
a common way to identify hidden patterns in the data such as outliers or
clusters. The fixed effects model only makes assumptions about the
dimensionality of the data, and incorporates knowledge about noise in
the data to improve estimates. The results of the paper were that the
fixed effects model incorporating CPCA (common PCA) out preformed all
others. [@duras2022fixed]]{style="color: #8B814C;"}

[**6. Microaneurysm Detection Using Principal Component Analysis and
Machine Learning Methods**]{style="color: #8B814C;"}

[The Following paper follows the use of Principal Component Analysis and
Machine Learning Methods with recognizing Microanerysm. Here Diabetic
Retinopathy (DR) is a progressive disease with almost no early symptoms
of vision impairment,which is the leading cause of blindness prior to
the age. As a result The first detectable sign of DR is the presence of
microaneurysms (MAs), which result from leakage of tiny blood vessels in
the retina and manifest themselves as small red circular spots on the
surface of retinas. Early detection of MAs is critical for diagnosis and
treatment of DR, which has led to a great deal of research towards
automatic detection of MAs. The paper relays that Many existing MA
detection methods rely on hand-crafted features, which are often based
on low-level information. Lowlevel information is easily susceptible to
signal drift artifacts and thus prevent reliable generalization among
different research sites. A recent method \[1\] leveraged the use of
deep learning for MA detection using a Stacked Sparse Autoencoder
(SSAE). Deep learning approaches often learn high-level and robust
attributes directly from the raw signal input, and have been
successfully applied to various classification and recognition tasks
\[8\]--\[10\]. In \[1\], small image patches were generated from the
original fundus images and used by the SSAE to learn high-level features
from pixel intensities. These patches were then classified as either MA.
The goal is to determine whether traditional machine learning methods
can achieve similar or better performance on the same fundus image
dataset by exploring the full context of the image information,
especially when the size of the dataset may be too limited for reliably
training deep learning The Dataset analyzed DIARETDB1 \[11\] images that
were acquired from 89 patients, in which each image was manually
annotated by multiple experts at Kuopio hospital. 84 of the 89 patients
contained at least mild non-proliferative signs of DR, while the
remaining five patients were healthy with no signs of DR. Classification
of MA vs non-MA patches was performed using three sets of features. The
first feature set consisted of raw pixel intensities, rasterized from
the image patch. principal component analysis (PCA). A common feature
dimensionality reduction method. PCA projects data onto a new space in
which consecutive dimensions contain less and less of the variance of
the original data space and compresses the most important information
onto a subspace with lower dimensionality than the original space. The
machine learning methods employed in this work include RF, NN, and SVM.
the methods outperformed previous work that conducted deep learning
using the same database, measured by both AUC and F-measure. Further
validation of our method on a different dataset ROC showed similar
results as we found on DIARETDB1. Our results yield a promising step
towards automated early detection of microaneurysms and diabetic
retinopathy. Three interesting results were observed in our findings.
First, after application of PCA to the original 625-dimensional
dataspace, SVMs achieved near maximum performance using only 30% of
data. With the incorporation of more principal components, the
performance of the SVM plateaued, while the performance of the RF and NN
both decreased. Second, by reducing dimensionality using RF feature
importance, they were able to achieve high AUC with fewer dimensions and
maintain this high AUC as more dimensions were included. Third, when we
trained the random forest on DIARETDB1 and used ROC as the testing data,
the performance was similar as that achieved by the random forest
trained and tested on the ROC dataset using cross-validation.
[@Cao2018]]{style="color: #8B814C;"}

[**7. PCA-based polling strategy in machine learning framework for
coronary artery disease risk assessment in intravascular ultrasound: A
link between carotid and coronary grayscale plaque
morphology**]{style="color: #8B814C;"}

[The following paper reflects on a novel strategy for risk
stratification based on plaque morphology embedded with principal
component analysis (PCA) for plaque feature dimensionality reduction and
dominant feature selection technique. The paper leads the major cause of
morbidity in the world is due to cardiovascular disease (CVD). These
diseases occur due to atherosclerosis a progressive and slow process of
narrowing the artery, interrupting the flow of blood from the heart or
to the brain. Today The current-state-of-art methods for screening the
severity of this disease is: computed tomography (CT), ultrasound(US),
and magnetic resonance imaging (MRI). However Due to radiation ,CT may
compromise the patients' safety, but it is often used because it
computes a calcium score in the coronary artery. It cover two hypothesis
: First : We thus hypothesize that different components offer different
risk factors and when combined as a whole using the grayscale wall
region image can be used for tissue characterization. We can thus
lever-age to study the morphological characteristics of these lesions
and adapt a machine learning paradigm to predict the risk of severity of
CAD leading to myocardial infarction. Here the paper will explores the
novel concept of morphological characteristics utilizing the coronary
vessel wall region that possesses these plaque components. Second : They
hypothesize that cIMT can be adapted for developing a link between the
coronary plaque burden leading to coronary artery disease or carotid
artery disease leading to stroke. This is due to the correlation between
automated cIMT that includes bulb plaque and SYNTAX score. Based on the
experiment regarding the role of the two hypotheses, they present the
two experimental protocols based on that foundation. The two major
hypotheses were: (i) risk associated with the components of the coronary
artery vessel wall and (ii) ability of carotid IMT to characterize the
cardiovascular risk. There protocol design demonstrates the machine
learning paradigm for risk assessment using the combination of (a)
grayscale PCA-based dominant features of the coronary artery wall and
(b) the gold standard subclinical risk biomarker -- the carotid IMT
during the learning-phase that generates the offline coefficients. The
testing-phase utilizes the PCA-based dominant feature extraction which
is then transformed by the offline coefficients. Based on Results the
best feature combination using PCA-based polling. The section then
details which kernel function is best suitable using the PCA-based
optimization for a fixed data size N. It is then concluded that
presented a coronary artery risk assessment system by taking two key
hypothesis: (i) there is a coronary artery disease risk associated with
vessel wall region consisting of different plaque components such as:
fibrous, fibrolipidic, calcified and calcified-necrotic; (ii) coronary
risk label is derived using the carotid intima-media thickness biomarker
that was used as a gold standard for design and development of machine
learning system for coronary artery disease risk assessment and
stratification. The computer-aided diagnosis system based on machine
learning utilizing PCA-based feature selection criteria is able to
classify the high risk and low risk coronary artery disease patients
with high accuracy reaching close to 98.50%. We demonstrated that
PCA-based feature selection using polling method is highly suitable for
dominant features selection. The system showed a high reliability of
97.32% while meeting the stability criteria of 5%. The coronary artery
disease risk assessment is automated given the vessel wall region of the
coronary artery. The results are promising leading to the prototype
design for a clinical setup. [@Chen2017]]{style="color: #8B814C;"}

## [Methods]{style="color: #191970;"}

## [Analysis and Results]{style="color: #191970;"}

## [Data and Vizualisation]{style="color: #191970;"}

[Bacteria dataset from MASS package (220 rows by 6
columns)]{style="color: #8B814C;"}

[Dr A. Leach tested the effects of a drug on 50 children with a history
of otitis media in the Northern Territory of Australia. The children
were randomized to the drug or the a placebo, and also to receive active
encouragement to comply with taking the drug. The presence of H.
influenzae was checked at weeks 0, 2, 4, 6 and 11: 30 of the checks were
missing and are not included in this data
frame.]{style="color: #8B814C;"}

[**Variables**]{style="color: #8B814C;"}

[**y** - presence or absence: a factor with levels n and
y]{style="color: #8B814C;"}

[**ap** - active/placebo: a factor with levels a and
p]{style="color: #8B814C;"}

[**hilo** - hi/low compliance: a factor with levels hi amd
lo]{style="color: #8B814C;"}

[**week** - numeric: week of test]{style="color: #8B814C;"}

[**ID** - subject ID: a factor]{style="color: #8B814C;"}

[**trt** - a factor with levels placebo, drug and drug+, a re-coding of
ap and hilo]{style="color: #8B814C;"}

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
library(MASS)

```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(bacteria))

#ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  #ggplot1 + geom_point(aes(col=region), size = 4) +
  #geom_text_repel(aes(label=abb)) +
  #scale_x_log10() +
  #scale_y_log10() +
  #geom_smooth(formula = "y~x", method=lm,se = F)+
  #xlab("Populations in millions (log10 scale)") + 
  #ylab("Total number of murders (log10 scale)") +
  #ggtitle("US Gun Murders in 2010") +
  #scale_color_discrete(name = "Region")+
  #    theme_wsj()

```

## [Statistical Modeling]{style="color: #191970;"}

## [Conlusion]{style="color: #191970;"}

## [References]{style="color: #191970;"}
